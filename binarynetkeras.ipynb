{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install larq","metadata":{"execution":{"iopub.status.busy":"2023-05-10T09:07:39.940242Z","iopub.execute_input":"2023-05-10T09:07:39.940649Z","iopub.status.idle":"2023-05-10T09:07:54.787158Z","shell.execute_reply.started":"2023-05-10T09:07:39.940617Z","shell.execute_reply":"2023-05-10T09:07:54.785776Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting larq\n  Downloading larq-0.13.0-py3-none-any.whl (65 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting terminaltables>=3.1.0\n  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: packaging>=19.2 in /opt/conda/lib/python3.10/site-packages (from larq) (21.3)\nRequirement already satisfied: numpy<2.0,>=1.15.4 in /opt/conda/lib/python3.10/site-packages (from larq) (1.23.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=19.2->larq) (3.0.9)\nInstalling collected packages: terminaltables, larq\nSuccessfully installed larq-0.13.0 terminaltables-3.1.10\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras import Sequential\nfrom keras.utils import tf_utils\nfrom keras.engine import base_layer\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers.rnn.dropout_rnn_cell_mixin import DropoutRNNCellMixin\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.layers import Dense, LSTM\nimport larq\n\n\nimport uuid\nimport tensorflow.compat.v2 as tf\nfrom keras import activations\nfrom keras import backend\nfrom keras import constraints\nfrom keras import initializers\nfrom keras import regularizers\nfrom keras.engine import base_layer\nfrom keras.engine.input_spec import InputSpec\nfrom keras.layers.rnn import gru_lstm_utils\nfrom keras.layers.rnn import rnn_utils\nfrom keras.layers.rnn.base_rnn import RNN\nfrom keras.layers.rnn.dropout_rnn_cell_mixin import DropoutRNNCellMixin\nfrom keras.utils import tf_utils\n\n# isort: off\nfrom tensorflow.python.platform import tf_logging as logging\nfrom tensorflow.python.util.tf_export import keras_export","metadata":{"execution":{"iopub.status.busy":"2023-05-10T09:06:34.009363Z","iopub.execute_input":"2023-05-10T09:06:34.010208Z","iopub.status.idle":"2023-05-10T09:06:34.029494Z","shell.execute_reply.started":"2023-05-10T09:06:34.010157Z","shell.execute_reply":"2023-05-10T09:06:34.027415Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"class BinaryLSTMCell(DropoutRNNCellMixin, base_layer.BaseRandomLayer, larq.layers_base.BaseLayer):\n    def __init__(\n        self,\n        units,\n        activation=\"tanh\",\n        recurrent_activation=\"sigmoid\",\n        use_bias=True,\n        kernel_initializer=\"glorot_uniform\",\n        recurrent_initializer=\"orthogonal\",\n        bias_initializer=\"zeros\",\n        unit_forget_bias=True,\n        kernel_regularizer=None,\n        recurrent_regularizer=None,\n        bias_regularizer=None,\n        kernel_constraint=None,\n        recurrent_constraint=None,\n        bias_constraint=None,\n        #kernel_quantizer=None,\n        #recurrent_quantizer=None,\n        #input_quantizer=None,\n        dropout=0.0,\n        recurrent_dropout=0.0,\n        **kwargs,\n    ):\n        if units <= 0:\n            raise ValueError(\n                \"Received an invalid value for argument `units`, \"\n                f\"expected a positive integer, got {units}.\"\n            )\n        # By default use cached variable under v2 mode, see b/143699808.\n        if tf.compat.v1.executing_eagerly_outside_functions():\n            self._enable_caching_device = kwargs.pop(\n                \"enable_caching_device\", True\n            )\n        else:\n            self._enable_caching_device = kwargs.pop(\n                \"enable_caching_device\", False\n            )\n        super().__init__(**kwargs)\n        self.units = units\n        self.activation = activations.get(activation)\n        self.recurrent_activation = activations.get(recurrent_activation)\n        self.use_bias = use_bias\n\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.recurrent_initializer = initializers.get(recurrent_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.unit_forget_bias = unit_forget_bias\n\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.recurrent_constraint = constraints.get(recurrent_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n        \n        #self.kernel_quantizer = larq.quantizers.get(kernel_quantizer)\n        #self.recurrent_quantizer = larq.quantizers.get(recurrent_quantizer)\n        #self.input_quantizer = larq.quantizers.get(input_quantizer)\n        \n        self.dropout = min(1.0, max(0.0, dropout))\n        self.recurrent_dropout = min(1.0, max(0.0, recurrent_dropout))\n        implementation = kwargs.pop(\"implementation\", 2)\n        if self.recurrent_dropout != 0 and implementation != 1:\n            logging.debug(RECURRENT_DROPOUT_WARNING_MSG)\n            self.implementation = 1\n        else:\n            self.implementation = implementation\n        self.state_size = [self.units, self.units]\n        self.output_size = self.units\n\n    @tf_utils.shape_type_conversion\n    def build(self, input_shape):\n        super().build(input_shape)\n        default_caching_device = rnn_utils.caching_device(self)\n        input_dim = input_shape[-1]\n        self.kernel = self.add_weight(\n            shape=(input_dim, self.units * 4),\n            name=\"kernel\",\n            initializer=self.kernel_initializer,\n            regularizer=self.kernel_regularizer,\n            constraint=self.kernel_constraint,\n            caching_device=default_caching_device,\n        )\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units * 4),\n            name=\"recurrent_kernel\",\n            initializer=self.recurrent_initializer,\n            regularizer=self.recurrent_regularizer,\n            constraint=self.recurrent_constraint,\n            caching_device=default_caching_device,\n        )\n\n        if self.use_bias:\n            if self.unit_forget_bias:\n\n                def bias_initializer(_, *args, **kwargs):\n                    return backend.concatenate(\n                        [\n                            self.bias_initializer(\n                                (self.units,), *args, **kwargs\n                            ),\n                            initializers.get(\"ones\")(\n                                (self.units,), *args, **kwargs\n                            ),\n                            self.bias_initializer(\n                                (self.units * 2,), *args, **kwargs\n                            ),\n                        ]\n                    )\n\n            else:\n                bias_initializer = self.bias_initializer\n            self.bias = self.add_weight(\n                shape=(self.units * 4,),\n                name=\"bias\",\n                initializer=bias_initializer,\n                regularizer=self.bias_regularizer,\n                constraint=self.bias_constraint,\n                caching_device=default_caching_device,\n            )\n        else:\n            self.bias = None\n        self.built = True\n\n    def _compute_carry_and_output(self, x, h_tm1, c_tm1):\n        \"\"\"Computes carry and output using split kernels.\"\"\"\n        x_i, x_f, x_c, x_o = x\n        h_tm1_i, h_tm1_f, h_tm1_c, h_tm1_o = h_tm1\n        i = self.recurrent_activation(\n            x_i + backend.dot(h_tm1_i, self.recurrent_kernel[:, : self.units])\n        )\n        f = self.recurrent_activation(\n            x_f\n            + backend.dot(\n                h_tm1_f, self.recurrent_kernel[:, self.units : self.units * 2]\n            )\n        )\n        c = f * c_tm1 + i * self.activation(\n            x_c\n            + backend.dot(\n                h_tm1_c,\n                self.recurrent_kernel[:, self.units * 2 : self.units * 3],\n            )\n        )\n        o = self.recurrent_activation(\n            x_o\n            + backend.dot(h_tm1_o, self.recurrent_kernel[:, self.units * 3 :])\n        )\n        return c, o\n\n    def _compute_carry_and_output_fused(self, z, c_tm1):\n        \"\"\"Computes carry and output using fused kernels.\"\"\"\n        z0, z1, z2, z3 = z\n        i = self.recurrent_activation(z0)\n        f = self.recurrent_activation(z1)\n        c = f * c_tm1 + i * self.activation(z2)\n        o = self.recurrent_activation(z3)\n        return c, o\n\n    def call(self, inputs, states, training=None):\n        h_tm1 = states[0]  # previous memory state\n        c_tm1 = states[1]  # previous carry state\n\n        dp_mask = self.get_dropout_mask_for_cell(inputs, training, count=4)\n        rec_dp_mask = self.get_recurrent_dropout_mask_for_cell(\n            h_tm1, training, count=4\n        )\n\n        if self.implementation == 1:\n            if 0 < self.dropout < 1.0:\n                inputs_i = inputs * dp_mask[0]\n                inputs_f = inputs * dp_mask[1]\n                inputs_c = inputs * dp_mask[2]\n                inputs_o = inputs * dp_mask[3]\n            else:\n                inputs_i = inputs\n                inputs_f = inputs\n                inputs_c = inputs\n                inputs_o = inputs\n            k_i, k_f, k_c, k_o = tf.split(\n                self.kernel, num_or_size_splits=4, axis=1\n            )\n            x_i = backend.dot(inputs_i, k_i)\n            x_f = backend.dot(inputs_f, k_f)\n            x_c = backend.dot(inputs_c, k_c)\n            x_o = backend.dot(inputs_o, k_o)\n            if self.use_bias:\n                b_i, b_f, b_c, b_o = tf.split(\n                    self.bias, num_or_size_splits=4, axis=0\n                )\n                x_i = backend.bias_add(x_i, b_i)\n                x_f = backend.bias_add(x_f, b_f)\n                x_c = backend.bias_add(x_c, b_c)\n                x_o = backend.bias_add(x_o, b_o)\n\n            if 0 < self.recurrent_dropout < 1.0:\n                h_tm1_i = h_tm1 * rec_dp_mask[0]\n                h_tm1_f = h_tm1 * rec_dp_mask[1]\n                h_tm1_c = h_tm1 * rec_dp_mask[2]\n                h_tm1_o = h_tm1 * rec_dp_mask[3]\n            else:\n                h_tm1_i = h_tm1\n                h_tm1_f = h_tm1\n                h_tm1_c = h_tm1\n                h_tm1_o = h_tm1\n            x = (x_i, x_f, x_c, x_o)\n            h_tm1 = (h_tm1_i, h_tm1_f, h_tm1_c, h_tm1_o)\n            c, o = self._compute_carry_and_output(x, h_tm1, c_tm1)\n        else:\n            if 0.0 < self.dropout < 1.0:\n                inputs = inputs * dp_mask[0]\n            z = backend.dot(inputs, self.kernel)\n            z += backend.dot(h_tm1, self.recurrent_kernel)\n            if self.use_bias:\n                z = backend.bias_add(z, self.bias)\n\n            z = tf.split(z, num_or_size_splits=4, axis=1)\n            c, o = self._compute_carry_and_output_fused(z, c_tm1)\n\n        h = o * self.activation(c)\n        return h, [h, c]\n\n    def get_config(self):\n        config = {\n            \"units\": self.units,\n            \"activation\": activations.serialize(self.activation),\n            \"recurrent_activation\": activations.serialize(\n                self.recurrent_activation\n            ),\n            \"use_bias\": self.use_bias,\n            \"kernel_initializer\": initializers.serialize(\n                self.kernel_initializer\n            ),\n            \"recurrent_initializer\": initializers.serialize(\n                self.recurrent_initializer\n            ),\n            \"bias_initializer\": initializers.serialize(self.bias_initializer),\n            \"unit_forget_bias\": self.unit_forget_bias,\n            \"kernel_regularizer\": regularizers.serialize(\n                self.kernel_regularizer\n            ),\n            \"recurrent_regularizer\": regularizers.serialize(\n                self.recurrent_regularizer\n            ),\n            \"bias_regularizer\": regularizers.serialize(self.bias_regularizer),\n            \"kernel_constraint\": constraints.serialize(self.kernel_constraint),\n            \"recurrent_constraint\": constraints.serialize(\n                self.recurrent_constraint\n            ),\n            \"bias_constraint\": constraints.serialize(self.bias_constraint),\n            \"dropout\": self.dropout,\n            \"recurrent_dropout\": self.recurrent_dropout,\n            \"implementation\": self.implementation,\n        }\n        config.update(rnn_utils.config_for_enable_caching_device(self))\n        base_config = super().get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n        return list(\n            rnn_utils.generate_zero_filled_state_for_cell(\n                self, inputs, batch_size, dtype\n            )\n        )\n\nclass BinaryLSTM(DropoutRNNCellMixin, RNN, base_layer.BaseRandomLayer, larq.layers_base.BaseLayer):\n    def __init__(\n        self,\n        units,\n        activation=\"tanh\",\n        recurrent_activation=\"sigmoid\",\n        use_bias=True,\n        kernel_initializer=\"glorot_uniform\",\n        recurrent_initializer=\"orthogonal\",\n        bias_initializer=\"zeros\",\n        unit_forget_bias=True,\n        kernel_regularizer=None,\n        recurrent_regularizer=None,\n        bias_regularizer=None,\n        activity_regularizer=None,\n        kernel_constraint=None,\n        recurrent_constraint=None,\n        bias_constraint=None,\n        #kernel_quantizer=None,\n        #recurrent_quantizer=None,\n        #input_quantizer=None,\n        dropout=0.0,\n        recurrent_dropout=0.0,\n        return_sequences=False,\n        return_state=False,\n        go_backwards=False,\n        stateful=False,\n        time_major=False,\n        unroll=False,\n        **kwargs,\n    ):\n        # return_runtime is a flag for testing, which shows the real backend\n        # implementation chosen by grappler in graph mode.\n        self.return_runtime = kwargs.pop(\"return_runtime\", False)\n        implementation = kwargs.pop(\"implementation\", 2)\n        if implementation == 0:\n            logging.warning(\n                \"`implementation=0` has been deprecated, \"\n                \"and now defaults to `implementation=1`.\"\n                \"Please update your layer call.\"\n            )\n        if \"enable_caching_device\" in kwargs:\n            cell_kwargs = {\n                \"enable_caching_device\": kwargs.pop(\"enable_caching_device\")\n            }\n        else:\n            cell_kwargs = {}\n        cell = BinaryLSTMCell(\n            units,\n            activation=activation,\n            recurrent_activation=recurrent_activation,\n            use_bias=use_bias,\n            kernel_initializer=kernel_initializer,\n            recurrent_initializer=recurrent_initializer,\n            unit_forget_bias=unit_forget_bias,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            recurrent_regularizer=recurrent_regularizer,\n            bias_regularizer=bias_regularizer,\n            kernel_constraint=kernel_constraint,\n            recurrent_constraint=recurrent_constraint,\n            bias_constraint=bias_constraint,\n            #kernel_quantizer=kernel_quantizer,\n            #recurrent_quantizer=None,\n            #input_quantizer=input_quantizer,\n            dropout=dropout,\n            recurrent_dropout=recurrent_dropout,\n            implementation=implementation,\n            dtype=kwargs.get(\"dtype\"),\n            trainable=kwargs.get(\"trainable\", True),\n            **cell_kwargs,\n        )\n        super().__init__(\n            cell,\n            return_sequences=return_sequences,\n            return_state=return_state,\n            go_backwards=go_backwards,\n            stateful=stateful,\n            time_major=time_major,\n            unroll=unroll,\n            **kwargs,\n        )\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.input_spec = [InputSpec(ndim=3)]\n        self.state_spec = [\n            InputSpec(shape=(None, dim)) for dim in (self.units, self.units)\n        ]\n        self._could_use_gpu_kernel = (\n            self.activation in (activations.tanh, tf.tanh)\n            and self.recurrent_activation in (activations.sigmoid, tf.sigmoid)\n            and recurrent_dropout == 0\n            and not unroll\n            and use_bias\n            and tf.compat.v1.executing_eagerly_outside_functions()\n        )\n        if tf.config.list_logical_devices(\"GPU\"):\n            # Only show the message when there is GPU available, user will not\n            # care about the cuDNN if there isn't any GPU.\n            if self._could_use_gpu_kernel:\n                logging.debug(gru_lstm_utils.CUDNN_AVAILABLE_MSG % self.name)\n            else:\n                logging.warning(\n                    gru_lstm_utils.CUDNN_NOT_AVAILABLE_MSG % self.name\n                )\n\n        if gru_lstm_utils.use_new_gru_lstm_impl():\n            self._defun_wrapper = gru_lstm_utils.DefunWrapper(\n                time_major, go_backwards, \"lstm\"\n            )\n\n    def call(self, inputs, mask=None, training=None, initial_state=None):\n        # The input should be dense, padded with zeros. If a ragged input is fed\n        # into the layer, it is padded and the row lengths are used for masking.\n        inputs, row_lengths = backend.convert_inputs_if_ragged(inputs)\n        is_ragged_input = row_lengths is not None\n        self._validate_args_if_ragged(is_ragged_input, mask)\n\n        # LSTM does not support constants. Ignore it during process.\n        inputs, initial_state, _ = self._process_inputs(\n            inputs, initial_state, None\n        )\n\n        if isinstance(mask, list):\n            mask = mask[0]\n\n        input_shape = backend.int_shape(inputs)\n        timesteps = input_shape[0] if self.time_major else input_shape[1]\n\n        if not self._could_use_gpu_kernel:\n            # Fall back to use the normal LSTM.\n            kwargs = {\"training\": training}\n            self._maybe_reset_cell_dropout_mask(self.cell)\n\n            def step(inputs, states):\n                return self.cell(inputs, states, **kwargs)\n\n            last_output, outputs, states = backend.rnn(\n                step,\n                inputs,\n                initial_state,\n                constants=None,\n                go_backwards=self.go_backwards,\n                mask=mask,\n                unroll=self.unroll,\n                input_length=row_lengths\n                if row_lengths is not None\n                else timesteps,\n                time_major=self.time_major,\n                zero_output_for_mask=self.zero_output_for_mask,\n                return_all_outputs=self.return_sequences,\n            )\n            runtime = gru_lstm_utils.runtime(gru_lstm_utils.RUNTIME_UNKNOWN)\n        else:\n            # Use the new defun approach for backend implementation swap.\n            # Note that different implementations need to have same function\n            # signature, eg, the tensor parameters need to have same shape and\n            # dtypes. Since the cuDNN has an extra set of bias, those bias will\n            # be passed to both normal and cuDNN implementations.\n            self.reset_dropout_mask()\n            dropout_mask = self.get_dropout_mask_for_cell(\n                inputs, training, count=4\n            )\n            if dropout_mask is not None:\n                inputs = inputs * dropout_mask[0]\n            if gru_lstm_utils.use_new_gru_lstm_impl():\n                lstm_kwargs = {\n                    \"inputs\": inputs,\n                    \"init_h\": gru_lstm_utils.read_variable_value(\n                        initial_state[0]\n                    ),\n                    \"init_c\": gru_lstm_utils.read_variable_value(\n                        initial_state[1]\n                    ),\n                    \"kernel\": gru_lstm_utils.read_variable_value(\n                        self.cell.kernel\n                    ),\n                    \"recurrent_kernel\": gru_lstm_utils.read_variable_value(\n                        self.cell.recurrent_kernel\n                    ),\n                    \"bias\": gru_lstm_utils.read_variable_value(self.cell.bias),\n                    \"mask\": mask,\n                    \"time_major\": self.time_major,\n                    \"go_backwards\": self.go_backwards,\n                    \"sequence_lengths\": row_lengths,\n                    \"zero_output_for_mask\": self.zero_output_for_mask,\n                }\n                (\n                    last_output,\n                    outputs,\n                    new_h,\n                    new_c,\n                    runtime,\n                ) = self._defun_wrapper.defun_layer(**lstm_kwargs)\n            else:\n                gpu_lstm_kwargs = {\n                    \"inputs\": inputs,\n                    \"init_h\": gru_lstm_utils.read_variable_value(\n                        initial_state[0]\n                    ),\n                    \"init_c\": gru_lstm_utils.read_variable_value(\n                        initial_state[1]\n                    ),\n                    \"kernel\": gru_lstm_utils.read_variable_value(\n                        self.cell.kernel\n                    ),\n                    \"recurrent_kernel\": gru_lstm_utils.read_variable_value(\n                        self.cell.recurrent_kernel\n                    ),\n                    \"bias\": gru_lstm_utils.read_variable_value(self.cell.bias),\n                    \"mask\": mask,\n                    \"time_major\": self.time_major,\n                    \"go_backwards\": self.go_backwards,\n                    \"sequence_lengths\": row_lengths,\n                    \"return_sequences\": self.return_sequences,\n                }\n                normal_lstm_kwargs = gpu_lstm_kwargs.copy()\n                normal_lstm_kwargs.update(\n                    {\n                        \"zero_output_for_mask\": self.zero_output_for_mask,\n                    }\n                )\n\n                if tf.executing_eagerly():\n                    device_type = gru_lstm_utils.get_context_device_type()\n                    can_use_gpu = (\n                        # Either user specified GPU or unspecified but GPU is\n                        # available.\n                        (\n                            device_type == gru_lstm_utils.GPU_DEVICE_NAME\n                            or (\n                                device_type is None\n                                and tf.config.list_logical_devices(\"GPU\")\n                            )\n                        )\n                        and gru_lstm_utils.is_cudnn_supported_inputs(\n                            mask, self.time_major, row_lengths\n                        )\n                    )\n                    # Under eager context, check the device placement and prefer\n                    # the GPU implementation when GPU is available.\n                    if can_use_gpu:\n                        last_output, outputs, new_h, new_c, runtime = gpu_lstm(\n                            **gpu_lstm_kwargs\n                        )\n                    else:\n                        (\n                            last_output,\n                            outputs,\n                            new_h,\n                            new_c,\n                            runtime,\n                        ) = standard_lstm(**normal_lstm_kwargs)\n                else:\n                    (\n                        last_output,\n                        outputs,\n                        new_h,\n                        new_c,\n                        runtime,\n                    ) = lstm_with_backend_selection(**normal_lstm_kwargs)\n\n            states = [new_h, new_c]\n\n        if self.stateful:\n            updates = [\n                tf.compat.v1.assign(\n                    self_state, tf.cast(state, self_state.dtype)\n                )\n                for self_state, state in zip(self.states, states)\n            ]\n            self.add_update(updates)\n\n        if self.return_sequences:\n            output = backend.maybe_convert_to_ragged(\n                is_ragged_input,\n                outputs,\n                row_lengths,\n                go_backwards=self.go_backwards,\n            )\n        else:\n            output = last_output\n\n        if self.return_state:\n            return [output] + list(states)\n        elif self.return_runtime:\n            return output, runtime\n        else:\n            return output\n\n    @property\n    def units(self):\n        return self.cell.units\n\n    @property\n    def activation(self):\n        return self.cell.activation\n\n    @property\n    def recurrent_activation(self):\n        return self.cell.recurrent_activation\n\n    @property\n    def use_bias(self):\n        return self.cell.use_bias\n\n    @property\n    def kernel_initializer(self):\n        return self.cell.kernel_initializer\n\n    @property\n    def recurrent_initializer(self):\n        return self.cell.recurrent_initializer\n\n    @property\n    def bias_initializer(self):\n        return self.cell.bias_initializer\n\n    @property\n    def unit_forget_bias(self):\n        return self.cell.unit_forget_bias\n\n    @property\n    def kernel_regularizer(self):\n        return self.cell.kernel_regularizer\n\n    @property\n    def recurrent_regularizer(self):\n        return self.cell.recurrent_regularizer\n\n    @property\n    def bias_regularizer(self):\n        return self.cell.bias_regularizer\n\n    @property\n    def kernel_constraint(self):\n        return self.cell.kernel_constraint\n\n    @property\n    def recurrent_constraint(self):\n        return self.cell.recurrent_constraint\n\n    @property\n    def bias_constraint(self):\n        return self.cell.bias_constraint\n\n    @property\n    def dropout(self):\n        return self.cell.dropout\n\n    @property\n    def recurrent_dropout(self):\n        return self.cell.recurrent_dropout\n\n    @property\n    def implementation(self):\n        return self.cell.implementation\n\n    def get_config(self):\n        config = {\n            \"units\": self.units,\n            \"activation\": activations.serialize(self.activation),\n            \"recurrent_activation\": activations.serialize(\n                self.recurrent_activation\n            ),\n            \"use_bias\": self.use_bias,\n            \"kernel_initializer\": initializers.serialize(\n                self.kernel_initializer\n            ),\n            \"recurrent_initializer\": initializers.serialize(\n                self.recurrent_initializer\n            ),\n            \"bias_initializer\": initializers.serialize(self.bias_initializer),\n            \"unit_forget_bias\": self.unit_forget_bias,\n            \"kernel_regularizer\": regularizers.serialize(\n                self.kernel_regularizer\n            ),\n            \"recurrent_regularizer\": regularizers.serialize(\n                self.recurrent_regularizer\n            ),\n            \"bias_regularizer\": regularizers.serialize(self.bias_regularizer),\n            \"activity_regularizer\": regularizers.serialize(\n                self.activity_regularizer\n            ),\n            \"kernel_constraint\": constraints.serialize(self.kernel_constraint),\n            \"recurrent_constraint\": constraints.serialize(\n                self.recurrent_constraint\n            ),\n            \"bias_constraint\": constraints.serialize(self.bias_constraint),\n            \"dropout\": self.dropout,\n            \"recurrent_dropout\": self.recurrent_dropout,\n            \"implementation\": self.implementation,\n        }\n        config.update(rnn_utils.config_for_enable_caching_device(self.cell))\n        base_config = super().get_config()\n        del base_config[\"cell\"]\n        return dict(list(base_config.items()) + list(config.items()))\n\n    @classmethod\n    def from_config(cls, config):\n        if \"implementation\" in config and config[\"implementation\"] == 0:\n            config[\"implementation\"] = 1\n        return cls(**config)\n\ndef standard_lstm(\n    inputs,\n    init_h,\n    init_c,\n    kernel,\n    recurrent_kernel,\n    bias,\n    mask,\n    time_major,\n    go_backwards,\n    sequence_lengths,\n    zero_output_for_mask,\n    return_sequences,\n):\n    input_shape = backend.int_shape(inputs)\n    timesteps = input_shape[0] if time_major else input_shape[1]\n\n    def step(cell_inputs, cell_states):\n        \"\"\"Step function that will be used by Keras RNN backend.\"\"\"\n        h_tm1 = cell_states[0]  # previous memory state\n        c_tm1 = cell_states[1]  # previous carry state\n        #quant = larq.quantizers.SteSign(clip_value=1.0)\n        #kernel = quant(kernel)\n        #recurrent_kernel = quant(recurrent_kernel)\n        z = backend.dot(cell_inputs, kernel)\n        z += backend.dot(h_tm1, recurrent_kernel)\n        z = backend.bias_add(z, bias)\n\n        z0, z1, z2, z3 = tf.split(z, 4, axis=1)\n\n        i = tf.sigmoid(z0)\n        f = tf.sigmoid(z1)\n        c = f * c_tm1 + i * tf.tanh(z2)\n        o = tf.sigmoid(z3)\n\n        h = o * tf.tanh(c)\n        return h, [h, c]\n\n    last_output, outputs, new_states = backend.rnn(\n        step,\n        inputs,\n        [init_h, init_c],\n        constants=None,\n        unroll=False,\n        time_major=time_major,\n        mask=mask,\n        go_backwards=go_backwards,\n        input_length=(\n            sequence_lengths if sequence_lengths is not None else timesteps\n        ),\n        zero_output_for_mask=zero_output_for_mask,\n        return_all_outputs=return_sequences,\n    )\n    return (\n        last_output,\n        outputs,\n        new_states[0],\n        new_states[1],\n        gru_lstm_utils.runtime(gru_lstm_utils.RUNTIME_CPU),\n    )\n\ndef lstm_with_backend_selection(\n    inputs,\n    init_h,\n    init_c,\n    kernel,\n    recurrent_kernel,\n    bias,\n    mask,\n    time_major,\n    go_backwards,\n    sequence_lengths,\n    zero_output_for_mask,\n    return_sequences,\n):\n    \"\"\"Call the LSTM with optimized backend kernel selection.\n\n    Under the hood, this function will create two TF function, one with the most\n    generic kernel and can run on all device condition, and the second one with\n    cuDNN specific kernel, which can only run on GPU.\n\n    The first function will be called with normal_lstm_params, while the second\n    function is not called, but only registered in the graph. The Grappler will\n    do the proper graph rewrite and swap the optimized TF function based on the\n    device placement.\n\n    Args:\n      inputs: Input tensor of LSTM layer.\n      init_h: Initial state tensor for the cell output.\n      init_c: Initial state tensor for the cell hidden state.\n      kernel: Weights for cell kernel.\n      recurrent_kernel: Weights for cell recurrent kernel.\n      bias: Weights for cell kernel bias and recurrent bias. Only recurrent bias\n        is used in this case.\n      mask: Boolean tensor for mask out the steps within sequence.\n        An individual `True` entry indicates that the corresponding timestep\n        should be utilized, while a `False` entry indicates that the\n        corresponding timestep should be ignored.\n      time_major: Boolean, whether the inputs are in the format of\n        [time, batch, feature] or [batch, time, feature].\n      go_backwards: Boolean (default False). If True, process the input sequence\n        backwards and return the reversed sequence.\n      sequence_lengths: The lengths of all sequences coming from a variable\n        length input, such as ragged tensors. If the input has a fixed timestep\n        size, this should be None.\n      zero_output_for_mask: Boolean, whether to output zero for masked timestep.\n      return_sequences: Boolean. If True, return the recurrent outputs for all\n        timesteps in the sequence. If False, only return the output for the\n        last timestep (which consumes less memory).\n\n    Returns:\n      List of output tensors, same as standard_lstm.\n    \"\"\"\n    params = {\n        \"inputs\": inputs,\n        \"init_h\": init_h,\n        \"init_c\": init_c,\n        \"kernel\": kernel,\n        \"recurrent_kernel\": recurrent_kernel,\n        \"bias\": bias,\n        \"mask\": mask,\n        \"time_major\": time_major,\n        \"go_backwards\": go_backwards,\n        \"sequence_lengths\": sequence_lengths,\n        \"zero_output_for_mask\": zero_output_for_mask,\n        \"return_sequences\": return_sequences,\n    }\n\n    def gpu_lstm_with_fallback(\n        inputs,\n        init_h,\n        init_c,\n        kernel,\n        recurrent_kernel,\n        bias,\n        mask,\n        time_major,\n        go_backwards,\n        sequence_lengths,\n        zero_output_for_mask,\n        return_sequences,\n    ):\n        \"\"\"Use cuDNN kernel when mask is none or strictly right padded.\"\"\"\n\n        def cudnn_lstm_fn():\n            return gpu_lstm(\n                inputs=inputs,\n                init_h=init_h,\n                init_c=init_c,\n                kernel=kernel,\n                recurrent_kernel=recurrent_kernel,\n                bias=bias,\n                mask=mask,\n                time_major=time_major,\n                go_backwards=go_backwards,\n                sequence_lengths=sequence_lengths,\n                return_sequences=return_sequences,\n            )\n\n        def stardard_lstm_fn():\n            return standard_lstm(\n                inputs=inputs,\n                init_h=init_h,\n                init_c=init_c,\n                kernel=kernel,\n                recurrent_kernel=recurrent_kernel,\n                bias=bias,\n                mask=mask,\n                time_major=time_major,\n                go_backwards=go_backwards,\n                sequence_lengths=sequence_lengths,\n                zero_output_for_mask=zero_output_for_mask,\n                return_sequences=return_sequences,\n            )\n\n        return tf.__internal__.smart_cond.smart_cond(\n            gru_lstm_utils.is_cudnn_supported_inputs(\n                mask, time_major, sequence_lengths\n            ),\n            true_fn=cudnn_lstm_fn,\n            false_fn=stardard_lstm_fn,\n        )\n\n    if gru_lstm_utils.use_new_gru_lstm_impl():\n        # Chooses the implementation dynamically based on the running device.\n        (\n            last_output,\n            outputs,\n            new_h,\n            new_c,\n            runtime,\n        ) = tf.__internal__.execute_fn_for_device(\n            {\n                gru_lstm_utils.CPU_DEVICE_NAME: lambda: standard_lstm(**params),\n                gru_lstm_utils.GPU_DEVICE_NAME: lambda: gpu_lstm_with_fallback(\n                    **params\n                ),\n            },\n            lambda: standard_lstm(**params),\n        )\n    else:\n        # Each time a `tf.function` is called, we will give it a unique\n        # identifiable API name, so that Grappler won't get confused when it\n        # sees multiple LSTM layers added into same graph, and it will be able\n        # to pair up the different implementations across them.\n        api_name = \"lstm_\" + str(uuid.uuid4())\n        supportive_attribute = {\n            \"time_major\": time_major,\n            \"go_backwards\": go_backwards,\n        }\n        defun_standard_lstm = gru_lstm_utils.generate_defun_backend(\n            api_name,\n            gru_lstm_utils.CPU_DEVICE_NAME,\n            standard_lstm,\n            supportive_attribute,\n        )\n        defun_gpu_lstm = gru_lstm_utils.generate_defun_backend(\n            api_name,\n            gru_lstm_utils.GPU_DEVICE_NAME,\n            gpu_lstm_with_fallback,\n            supportive_attribute,\n        )\n\n        # Call the normal LSTM impl and register the cuDNN impl function. The\n        # grappler will kick in during session execution to optimize the graph.\n        last_output, outputs, new_h, new_c, runtime = defun_standard_lstm(\n            **params\n        )\n        gru_lstm_utils.function_register(defun_gpu_lstm, **params)\n\n    return last_output, outputs, new_h, new_c, runtime","metadata":{"execution":{"iopub.status.busy":"2023-05-10T09:01:27.896193Z","iopub.execute_input":"2023-05-10T09:01:27.896577Z","iopub.status.idle":"2023-05-10T09:01:28.017736Z","shell.execute_reply.started":"2023-05-10T09:01:27.896549Z","shell.execute_reply":"2023-05-10T09:01:28.016566Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"inputs = tf.random.normal([32, 10, 8])\nlstm_b = tf.keras.layers.LSTM(4, kernel_constraint='weight_clip', activation='ste_sign', kernel_regularizer='ste_sign', recurrent_activation='ste_sign', return_sequences=True)\nlstm_k = tf.keras.layers.LSTM(4, kernel_constraint='weight_clip')\nlstm_a = tf.keras.layers.LSTM(4, activation='ste_sign')\nlstm = tf.keras.layers.LSTM(4)\noutput = lstm_b(inputs)\nprint(output.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T08:50:16.248041Z","iopub.execute_input":"2023-05-10T08:50:16.248470Z","iopub.status.idle":"2023-05-10T08:50:16.335993Z","shell.execute_reply.started":"2023-05-10T08:50:16.248436Z","shell.execute_reply":"2023-05-10T08:50:16.334987Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"(32, 10, 4)\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.constraints import Constraint\nfrom keras import backend as K\n\nclass WeightClip(Constraint):\n    '''Clips the weights incident to each hidden unit to be inside a range\n    '''\n    def __init__(self, c=1):\n        self.c = c\n\n    def __call__(self, p):\n        return K.clip(p, -self.c, self.c)\n\n    def get_config(self):\n        return {'name': self.__class__.__name__,\n                'c': self.c}\n\nb = BinaryLSTM(16,\n           kernel_constraint='weight_clip', \n           recurrent_constraint='weight_clip')\nb(inputs)\n\nb2 = BinaryLSTM(16,\n           kernel_constraint=WeightClip, \n           recurrent_constraint=WeightClip)\nb(inputs), b2(inputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Functional\nfrom keras.layers import Dense, Activation\nfrom keras import backend as k\n\n\ninputs = keras.Input(shape=(10,8))\nb = BinaryLSTM(16)\noutputs = b(inputs)\nmodel = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\nmodel.compile(loss='MSE', optimizer='adam')\noutputTensor = model.output #Or model.layers[index].output\nlistOfVariableTensors = model.trainable_weights\ngradients = tf.GradientTape(outputTensor, listOfVariableTensors)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T09:01:34.049233Z","iopub.execute_input":"2023-05-10T09:01:34.049612Z","iopub.status.idle":"2023-05-10T09:01:36.565085Z","shell.execute_reply.started":"2023-05-10T09:01:34.049582Z","shell.execute_reply":"2023-05-10T09:01:36.563433Z"},"trusted":true},"execution_count":97,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[97], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m inputs \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      7\u001b[0m b \u001b[38;5;241m=\u001b[39m BinaryLSTM(\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39moutputs, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSE\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/layers/rnn/base_rnn.py:556\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m inputs, initial_state, constants \u001b[38;5;241m=\u001b[39m rnn_utils\u001b[38;5;241m.\u001b[39mstandardize_args(\n\u001b[1;32m    552\u001b[0m     inputs, initial_state, constants, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_constants\n\u001b[1;32m    553\u001b[0m )\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m constants \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# input_spec to include them.\u001b[39;00m\n\u001b[1;32m    562\u001b[0m additional_inputs \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/tmp/__autograph_generated_fileyyqudqcj.py:169\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    167\u001b[0m can_use_gpu \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan_use_gpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    168\u001b[0m new_h \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_h\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 169\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_could_use_gpu_kernel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast_output\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mruntime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstates\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_6\u001b[39m():\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n","File \u001b[0;32m/tmp/__autograph_generated_fileyyqudqcj.py:153\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_5\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m can_use_gpu \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan_use_gpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    152\u001b[0m new_h \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_h\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 153\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgru_lstm_utils\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_new_gru_lstm_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast_output\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnew_c\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnew_h\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mruntime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m states \u001b[38;5;241m=\u001b[39m [ag__\u001b[38;5;241m.\u001b[39mld(new_h), ag__\u001b[38;5;241m.\u001b[39mld(new_c)]\n","File \u001b[0;32m/tmp/__autograph_generated_fileyyqudqcj.py:142\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_5.<locals>.else_body_4\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m can_use_gpu \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan_use_gpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m new_h \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_h\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 142\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecuting_eagerly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast_output\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnew_c\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnew_h\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mruntime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/tmp/__autograph_generated_fileyyqudqcj.py:134\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_5.<locals>.else_body_4.<locals>.else_body_3\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body_3\u001b[39m():\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m runtime, last_output, outputs, new_c, new_h\n\u001b[0;32m--> 134\u001b[0m     (last_output, outputs, new_h, new_c, runtime) \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_with_backend_selection\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormal_lstm_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/tmp/__autograph_generated_filekv462tvr.py:118\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__lstm_with_backend_selection\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask, return_sequences)\u001b[0m\n\u001b[1;32m    116\u001b[0m defun_gpu_lstm \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefun_gpu_lstm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    117\u001b[0m new_h \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_h\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 118\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgru_lstm_utils\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_new_gru_lstm_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast_output\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnew_c\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnew_h\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mruntime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[0;32m/tmp/__autograph_generated_filekv462tvr.py:108\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__lstm_with_backend_selection.<locals>.else_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m defun_gpu_lstm \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(gru_lstm_utils)\u001b[38;5;241m.\u001b[39mgenerate_defun_backend, (ag__\u001b[38;5;241m.\u001b[39mld(api_name), ag__\u001b[38;5;241m.\u001b[39mld(gru_lstm_utils)\u001b[38;5;241m.\u001b[39mGPU_DEVICE_NAME, ag__\u001b[38;5;241m.\u001b[39mld(gpu_lstm_with_fallback), ag__\u001b[38;5;241m.\u001b[39mld(supportive_attribute)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m    107\u001b[0m (last_output, outputs, new_h, new_c, runtime) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(defun_standard_lstm), (), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(params)), fscope)\n\u001b[0;32m--> 108\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgru_lstm_utils\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_register\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefun_gpu_lstm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/tmp/__autograph_generated_filekv462tvr.py:84\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__lstm_with_backend_selection.<locals>.gpu_lstm_with_fallback\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask, return_sequences)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     do_return_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     retval__1 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39msmart_cond\u001b[38;5;241m.\u001b[39msmart_cond, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(gru_lstm_utils)\u001b[38;5;241m.\u001b[39mis_cudnn_supported_inputs, (ag__\u001b[38;5;241m.\u001b[39mld(mask), ag__\u001b[38;5;241m.\u001b[39mld(time_major), ag__\u001b[38;5;241m.\u001b[39mld(sequence_lengths)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope_1),), \u001b[38;5;28mdict\u001b[39m(true_fn\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(cudnn_lstm_fn), false_fn\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(stardard_lstm_fn)), fscope_1)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     do_return_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"binary_lstm_60\" (type BinaryLSTM).\n\nin user code:\n\n    File \"/tmp/ipykernel_34/4076846995.py\", line 521, in call  *\n        (\n    File \"/tmp/ipykernel_34/4076846995.py\", line 851, in gpu_lstm_with_fallback  *\n        false_fn=stardard_lstm_fn,\n\n    TypeError: is_cudnn_supported_inputs() takes 2 positional arguments but 3 were given\n\n\nCall arguments received by layer \"binary_lstm_60\" (type BinaryLSTM):\n  • inputs=tf.Tensor(shape=(None, 10, 8), dtype=float32)\n  • mask=None\n  • training=None\n  • initial_state=None"],"ename":"TypeError","evalue":"Exception encountered when calling layer \"binary_lstm_60\" (type BinaryLSTM).\n\nin user code:\n\n    File \"/tmp/ipykernel_34/4076846995.py\", line 521, in call  *\n        (\n    File \"/tmp/ipykernel_34/4076846995.py\", line 851, in gpu_lstm_with_fallback  *\n        false_fn=stardard_lstm_fn,\n\n    TypeError: is_cudnn_supported_inputs() takes 2 positional arguments but 3 were given\n\n\nCall arguments received by layer \"binary_lstm_60\" (type BinaryLSTM):\n  • inputs=tf.Tensor(shape=(None, 10, 8), dtype=float32)\n  • mask=None\n  • training=None\n  • initial_state=None","output_type":"error"}]},{"cell_type":"code","source":"#gradients.gradient(tf.random.normal([1, 10, 16]), tf.random.normal([1, 10, 8]))\ninputs = tf.random.normal([32, 10, 8])\nwith tf.GradientTape() as g:\n  g.watch(inputs)\n  y = BinaryLSTM(16)(inputs)\ndy_dx = g.gradient(y, inputs)\nprint(dy_dx)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T08:54:02.025920Z","iopub.execute_input":"2023-05-10T08:54:02.026386Z","iopub.status.idle":"2023-05-10T08:54:02.152629Z","shell.execute_reply.started":"2023-05-10T08:54:02.026343Z","shell.execute_reply":"2023-05-10T08:54:02.151607Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[[-1.31315425e-01  7.51657858e-02 -4.87842672e-02 ... -5.16913459e-02\n   -8.76002237e-02 -6.26783147e-02]\n  [ 1.70952559e-01 -1.17122933e-01 -8.26510787e-02 ... -2.01966226e-01\n   -2.19702318e-01 -2.00928137e-01]\n  [ 9.28272456e-02 -1.08132735e-01  7.33102560e-02 ... -1.87893912e-01\n    1.01225778e-01  3.64908092e-02]\n  ...\n  [ 5.01184464e-01  7.46754229e-01  3.00400674e-01 ... -2.42336392e-01\n   -3.01377118e-01  1.69432566e-01]\n  [-5.72375774e-01 -1.18148875e+00 -5.05245209e-01 ... -9.45789337e-01\n   -9.69471931e-01 -3.62962127e-01]\n  [-6.99965656e-01  1.70535707e+00  1.55846000e-01 ... -1.03561330e+00\n   -3.41859221e-01 -8.88080657e-01]]\n\n [[ 5.81084974e-02  7.01218471e-03  3.42215896e-02 ... -4.79155518e-02\n   -1.52706340e-01 -1.54193193e-01]\n  [-8.91183615e-02  1.18971705e-01  1.02094293e-01 ...  1.95581242e-02\n    1.91353321e-01  1.91113427e-01]\n  [ 2.63124287e-01 -1.44877017e-01 -5.50894618e-01 ... -2.64368922e-01\n   -9.74131450e-02 -3.80264223e-02]\n  ...\n  [-4.18715656e-01  6.03047252e-01 -6.53157711e-01 ...  4.75769281e-01\n    1.11878324e+00 -3.64746064e-01]\n  [-4.70071137e-01  7.29497015e-01  2.50796199e-01 ... -1.09983468e+00\n    4.34864730e-01  7.50551045e-01]\n  [-3.16390693e-02 -6.15226030e-01 -6.50325537e-01 ... -4.65371966e-01\n   -7.18387604e-01  7.19014108e-02]]\n\n [[-1.41058832e-01 -1.44740045e-01 -1.36804700e-01 ...  7.59427845e-02\n   -4.08181064e-02 -1.24806911e-01]\n  [-5.84758930e-02  3.63598578e-02  2.32745968e-02 ... -1.81013588e-02\n    3.33216414e-02 -3.16484347e-02]\n  [-8.82216990e-02  1.57406181e-02  2.81699542e-02 ...  3.68423611e-02\n   -8.38735253e-02 -1.13117814e-01]\n  ...\n  [ 2.17506304e-01  7.16558397e-02  5.12251481e-02 ...  1.03143901e-02\n   -9.69177857e-02  8.88337418e-02]\n  [ 5.83470464e-01 -6.15754962e-01  5.86115599e-01 ...  2.13550627e-02\n   -7.94333339e-01 -5.66107750e-01]\n  [-1.11727759e-01 -1.14315860e-01  3.41031492e-01 ... -1.80718884e-01\n   -2.20261991e-01  1.40044987e-02]]\n\n ...\n\n [[-3.18119153e-02  2.42934972e-02 -1.90913379e-02 ...  7.24569038e-02\n   -9.13731828e-02 -3.02271917e-03]\n  [ 1.95473343e-01 -2.77850870e-02  4.30437401e-02 ...  1.09836876e-01\n   -4.33023944e-02 -3.36801186e-02]\n  [ 2.25671053e-01 -4.43036482e-03  2.46256351e-01 ... -1.23664796e-01\n   -4.13033098e-01  3.92650813e-02]\n  ...\n  [ 6.56068325e-01  1.34308040e-01  8.30896199e-02 ... -7.79154241e-01\n    7.88230777e-01  1.76703006e-01]\n  [ 6.10738575e-01  4.00220037e-01  5.66662587e-02 ... -8.79222691e-01\n   -2.05020815e-01 -1.32912129e-01]\n  [-1.25864387e+00  1.02003670e+00  1.36198890e+00 ... -9.05612350e-01\n   -1.77220511e+00 -1.01203966e+00]]\n\n [[ 1.02385283e-01  7.75821954e-02  3.63993794e-02 ... -1.92191124e-01\n   -1.26719981e-01  2.50525773e-05]\n  [-1.93972021e-01  9.37376767e-02  4.12481427e-01 ... -4.79116738e-02\n   -2.00428948e-01 -1.57923579e-01]\n  [ 2.04369470e-01 -1.16764084e-01  1.17024168e-01 ... -1.92612067e-01\n   -7.95504451e-02 -6.90363273e-02]\n  ...\n  [-1.33742303e-01 -4.36395183e-02 -2.59147763e-01 ...  2.15449870e-01\n   -1.44361973e-01 -2.48134449e-01]\n  [-8.79278898e-01  1.39373016e+00 -8.51449013e-01 ...  2.53944069e-01\n    1.00933206e+00 -8.15394580e-01]\n  [-8.76116306e-02 -3.15434575e-01 -1.18612990e-01 ... -1.98982552e-01\n    1.15086645e-01  2.30387956e-01]]\n\n [[-3.84948179e-02  1.04318932e-02  1.60405599e-03 ...  1.97750833e-02\n   -4.15916834e-03 -1.13067124e-02]\n  [-7.11122006e-02  2.11940091e-02 -2.55161189e-02 ... -3.23080271e-02\n    5.05518727e-02 -4.98924032e-03]\n  [ 2.58440198e-03  9.05408412e-02  1.47097511e-02 ... -3.47587932e-03\n    7.78719783e-04  2.00534891e-02]\n  ...\n  [ 6.09388351e-01  7.21493721e-01  4.52858299e-01 ...  2.24610120e-01\n   -1.73893496e-01  6.69994950e-01]\n  [-7.84858346e-01  9.76739287e-01  1.01809549e+00 ... -2.03921437e-01\n    1.12503040e+00  6.32628381e-01]\n  [-1.46345615e-01  1.08294427e-01  5.44414818e-02 ... -5.57063460e-01\n   -7.69650757e-01 -1.46692300e+00]]], shape=(32, 10, 8), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install keras==2.12.0 tensorflow==2.12.0","metadata":{"execution":{"iopub.status.busy":"2023-05-10T09:08:14.890850Z","iopub.execute_input":"2023-05-10T09:08:14.891246Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Collecting keras==2.12.0\n  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting tensorflow==2.12.0\n  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (0.29.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (3.20.3)\nCollecting wrapt<1.15,>=1.11.0\n  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.6.3)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (16.0.0)\nRequirement already satisfied: numpy<1.24,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.23.5)\nCollecting tensorboard<2.13,>=2.12\n  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (4.5.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.16.0)\nRequirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (0.4.8)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (23.3.3)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (3.3.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (3.8.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.4.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (2.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.53.0)\nCollecting tensorflow-estimator<2.13,>=2.12.0\n  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (0.2.0)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (0.4.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (59.8.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (21.3)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.40.0)\nRequirement already satisfied: ml-dtypes>=0.0.3 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.1.0)\nRequirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.9.3)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.17.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.2.3)\nCollecting google-auth-oauthlib<1.1,>=0.5\n  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\nCollecting tensorboard-data-server<0.8.0,>=0.7.0\n  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.28.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.12.0) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.3.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.1.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\nInstalling collected packages: wrapt, tensorflow-estimator, tensorboard-data-server, keras, google-auth-oauthlib, tensorboard, tensorflow\n  Attempting uninstall: wrapt\n    Found existing installation: wrapt 1.15.0\n    Uninstalling wrapt-1.15.0:\n      Successfully uninstalled wrapt-1.15.0\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.11.0\n    Uninstalling tensorflow-estimator-2.11.0:\n      Successfully uninstalled tensorflow-estimator-2.11.0\n  Attempting uninstall: tensorboard-data-server\n    Found existing installation: tensorboard-data-server 0.6.1\n    Uninstalling tensorboard-data-server-0.6.1:\n      Successfully uninstalled tensorboard-data-server-0.6.1\n  Attempting uninstall: keras\n    Found existing installation: keras 2.11.0\n    Uninstalling keras-2.11.0:\n      Successfully uninstalled keras-2.11.0\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 0.4.6\n    Uninstalling google-auth-oauthlib-0.4.6:\n      Successfully uninstalled google-auth-oauthlib-0.4.6\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.11.2\n    Uninstalling tensorboard-2.11.2:\n      Successfully uninstalled tensorboard-2.11.2\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.11.0\n    Uninstalling tensorflow-2.11.0:\n      Successfully uninstalled tensorflow-2.11.0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}